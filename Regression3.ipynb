{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9973ce0b-84a1-4981-902f-89f4e7ebfa6d",
   "metadata": {},
   "source": [
    "# Q1.\n",
    "### What is Ridge Regression, and how does it differ from ordinary least squares regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee23bf-7f8a-4c1d-8bc1-e8333e1d09c5",
   "metadata": {},
   "source": [
    "- Ridge Regression, is a linear regression technique that introduces a regularization term to the ordinary least squares (OLS) objective function. The regularization term is the sum of squared magnitudes of the coefficients multiplied by a hyperparameter.\n",
    "- Unlike OLS, which minimizes the sum of squared residuals, Ridge Regression adds a penalty term to prevent overfitting by discouraging large coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de9e3c-3d4a-458e-9143-b96f5459a7dc",
   "metadata": {},
   "source": [
    "# Q2.\n",
    "### What are the assumptions of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee35bf9-51df-41c8-ad00-48a3565025dc",
   "metadata": {},
   "source": [
    "- Ridge Regression assumes that the relationship between the independent variables and the dependent variable is linear.\n",
    "- It also assumes that the residuals are normally distributed and have constant variance.\n",
    "- Independence of observations is assumed, meaning that the values of the dependent variable are not influenced by the values of other observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f08dc7-6647-4442-b480-c66a1ecea3a7",
   "metadata": {},
   "source": [
    "# Q3.\n",
    "### How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ef33d-570f-495e-a9d8-c229187f3731",
   "metadata": {},
   "source": [
    "- The tuning parameter in Ridge Regression controls the strength of the regularization. The selection of this parameter involves a trade-off between fitting the data well and keeping the coefficients small.\n",
    "- Common methods for selecting the tuning parameter include cross-validation, where different values of lambda are tested on subsets of the data, and the one with the best performance is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef724f71-0ea2-4b1f-ace0-aa236ad706a7",
   "metadata": {},
   "source": [
    "# Q4.\n",
    "### Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce0200b-20d6-4e6b-9fd3-2cf63c399f39",
   "metadata": {},
   "source": [
    "- Ridge Regression does not perform feature selection in the traditional sense since it includes all features in the model. However, it can shrink the coefficients toward zero, which has a similar effect of downweighting less important features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c78786-e854-4a43-9921-f1b92c35bc2c",
   "metadata": {},
   "source": [
    "# Q5.\n",
    "### How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d18d86-299c-4c14-89da-1c9243fdd27f",
   "metadata": {},
   "source": [
    "- Ridge Regression is particularly useful when dealing with multicollinearity, a situation where independent variables are highly correlated. It tends to perform well in such cases by stabilizing the coefficients and preventing them from becoming too large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0beb41-4887-4208-bc35-e1b72b79ac75",
   "metadata": {},
   "source": [
    "# Q6.\n",
    "### Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a0593-aadc-47ae-9d6d-08e8b93067ed",
   "metadata": {},
   "source": [
    "- Ridge Regression can handle both categorical and continuous independent variables. Categorical variables are typically encoded into dummy variables before applying Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f249f9-1c47-4120-855e-2ec6d2739f8c",
   "metadata": {},
   "source": [
    "# Q7.\n",
    "### How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499a066-6c3a-48d3-8423-b29356874b83",
   "metadata": {},
   "source": [
    "- The coefficients in Ridge Regression should be interpreted with caution due to the regularization term. The size of the coefficients alone does not necessarily indicate the strength of the relationship. The interpretation is more about the relative importance of variables, and the coefficients are adjusted to prevent overemphasis on any particular variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6760539c-6391-4d74-8094-2eaa1ef53c55",
   "metadata": {},
   "source": [
    "# Q8.\n",
    "### Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ecafec-0527-490d-b472-bc80c0302590",
   "metadata": {},
   "source": [
    "- Ridge Regression can be applied to time-series data. However, when dealing with time-series data, other considerations such as autocorrelation and seasonality may need to be addressed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
